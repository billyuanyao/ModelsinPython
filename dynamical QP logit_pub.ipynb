{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import teradata\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=df[['bad_2','bad_1','bad_0']]\n",
    "y_logit=df.bad_flag\n",
    "y_cato=df.bad_cato\n",
    "y=df.bad_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=df[['wclaim_all_amt_90d','wcnt_gross_loss_30d','wdisp_all_amt_90d','wtpv_30d','wexposure','wbad_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import covariance\n",
    "covariance.empirical_covariance(x,assume_centered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mord as m\n",
    "ordmod= m.OrdinalRidge()\n",
    "ordmod.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordmod.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordmod.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordmod.unique_y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=ordmod.predict(x_test)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "x_a=x.iloc[:,0:2]\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_a,y_logit,test_size=0.3, random_state=0)\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = x_train.iloc[:, 0].min() - .5, x_train.iloc[:, 0].max() + .5\n",
    "y_min, y_max = x_train.iloc[:, 1].min() - .5, x_train.iloc[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(x_train.iloc[:, 0], x_train.iloc[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_min, x_max = x_train.iloc[:, 0].min() - .5, x_train.iloc[:, 0].max() + .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yy.ravel().shape,x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "\n",
    "for multi_class in ('multinomial', 'ovr'):\n",
    "    clf = LogisticRegression(solver='sag', max_iter=100, random_state=42,\n",
    "                             multi_class=multi_class).fit(x_train, y_train)\n",
    "\n",
    "    # print the training scores\n",
    "    print(\"training score : %.3f (%s)\" % (clf.score(x_train, y_train), multi_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y_cato,test_size=0.3, random_state=0)\n",
    "\n",
    "for multi_class in ('ovr', 'multinomial'):\n",
    "    clf_multi_class = LogisticRegression(solver='sag', max_iter=100, random_state=42,\n",
    "                             multi_class=multi_class).fit(x_train, y_train)\n",
    "\n",
    "    # print the training scores\n",
    "    print(\"training score : %.3f (%s)\" % (clf_multi_class.score(x_train, y_train), multi_class))\n",
    "    print(\"testing score : %.3f (%s)\" % (clf_multi_class.score(x_test, y_test), multi_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mord as m\n",
    "ordmod= m.OrdinalRidge()\n",
    "olg=ordmod.fit(x_train,y_train)\n",
    "print(\"training score : %.3f (%s) \" % (olg.score(x_train, y_train), 'ordinal'))\n",
    "print(\"testing score : %.3f (%s)\" % (olg.score(x_test, y_test),'ordinal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_multi_class.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_multi_class.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y_logit,test_size=0.3, random_state=0)\n",
    "clf_logit = LogisticRegression(solver='sag', max_iter=100, random_state=42).fit(x_train, y_train)\n",
    "# print the training scores\n",
    "print(\"training score : %.3f (%s)\" % (clf_logit.score(x_train, y_train),'logit'))\n",
    "print(\"testing score : %.3f (%s)\" % (clf_logit.score(x_test, y_test), 'logit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_multi_class.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_logit.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "n_classes = y.shape[1]\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(x_train, y_train).decision_function(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test.iloc[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.as_matrix().ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "'''\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "'''\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train on 0-2\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y_logit,test_size=0.3, random_state=0)\n",
    "clf_logit = LogisticRegression(solver='sag', max_iter=100, random_state=42).fit(x_train, y_train)\n",
    "# print the training scores\n",
    "print(\"training score : %.3f (%s)\" % (clf_logit.score(x_train, y_train),'logit'))\n",
    "print(\"testing score : %.3f (%s)\" % (clf_logit.score(x_test, y_test), 'logit'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "\n",
    "preds = clf_logit.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Binarize the output\n",
    "n_classes = y.shape[0]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = x.shape\n",
    "x = np.c_[x, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y_logit,test_size=0.3, random_state=0)\n",
    "clf_logit = LogisticRegression(solver='sag', max_iter=100, random_state=42).fit(x_train, y_train)\n",
    "\n",
    "y_score = classifier.fit(x_train, y_train).predict_proba(x_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#plot ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1=df.bad_flag1\n",
    "y2=df.bad_flag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=df[['wclaim_all_amt_90d','wcnt_gross_loss_30d','wdisp_all_amt_90d','wtpv_30d','wexposure','wbad_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train on 0-2\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y1,test_size=0.3, random_state=0)\n",
    "clf_logit1 = LogisticRegression(solver='sag', max_iter=100, random_state=42).fit(x_train, y_train)\n",
    "# print the training scores\n",
    "print(\"training score : %.3f (%s)\" % (clf_logit.score(x_train, y_train),'logit'))\n",
    "print(\"testing score : %.3f (%s)\" % (clf_logit.score(x_test, y_test), 'logit'))\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "\n",
    "preds = clf_logit1.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_logit1.coef_, clf_logit1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train on 0-2\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y2,test_size=0.3, random_state=0)\n",
    "clf_logit2 = LogisticRegression(solver='sag', max_iter=100, random_state=42).fit(x_train, y_train)\n",
    "# print the training scores\n",
    "print(\"training score : %.3f (%s)\" % (clf_logit.score(x_train, y_train),'logit'))\n",
    "print(\"testing score : %.3f (%s)\" % (clf_logit.score(x_test, y_test), 'logit'))\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "\n",
    "preds = clf_logit2.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_logit2.coef_, clf_logit2.intercept_, clf_logit2.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2=df[['wagent_riskfound_rate_2','wtpv_90d_2','wach_wd_amt_90d_2','wwd_all_cnt_90d_2','wach_tpv_amt_90d_2','wwd_all_amt_90d_2','wclaim_all_amt_7d_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2=df.bad_flag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train on 0-2\n",
    "x_train,x_test,y_train,y_test = train_test_split(x2,y2,test_size=0.3, random_state=0)\n",
    "clf_logit1 = LogisticRegression(solver='sag', max_iter=100, random_state=42).fit(x_train, y_train)\n",
    "# print the training scores\n",
    "print(\"training score : %.3f (%s)\" % (clf_logit1.score(x_train, y_train),'logit'))\n",
    "print(\"testing score : %.3f (%s)\" % (clf_logit1.score(x_test, y_test), 'logit'))\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "\n",
    "preds = clf_logit1.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clf_logit1.predict_proba(x_train)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_train, preds)\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_logit1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_logit1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
